---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a tenure-track associate professor at the Artificial Intelligence Research Institute of Shenzhen MSU-BIT University, China. I received my Bachelorâ€™s Degree in Automation in 2015 and my Ph.D. in Software Engineering in 2021, both from the South China University of Technology, under the supervision of Prof. Mingkui Tan and Dr. Chuang Gan. My research interests span machine learning and deep learning with a focus on their applications in video understanding and AI+Health. I have a particular interest in the multimodal information-based assessment and analysis of health, mental, and psychological states. I have published more than 20 papers at the top international AI conferences with total <a href='https://scholar.google.com.sg/citations?user=s3X4YHwAAAAJ&hl=en'>google scholar citations <strong><span id='total_cit'>1400+</span></strong></a>.


# ğŸ”¥ News
- &nbsp;ğŸ‰ğŸ‰ Two papers on video analysis is accepted by CVPR 2024 (1 oral (90 of the 2719 accepted papers) + 1 poster).
- &nbsp;ğŸ‰ğŸ‰ One paper on vision-and-language navigatio is accepted by NeurIPS 2023.
- &nbsp;ğŸ‰ğŸ‰ One paper on video test-time adaptation is accepted by ACM MM 2023.
- &nbsp;ğŸ‰ğŸ‰ I am serving as a reviewer for CVPR 2023, ICCV 2023, NeurIPS 2023.
- &nbsp;ğŸ‰ğŸ‰ One paper on vision-and-language navigation is accepted by NeurIPS 2022.
- &nbsp;ğŸ‰ğŸ‰ I am serving as a reviewer for CVPR 2022, ICML 2022, ECCV 2022, NeurIPS 2022.
- &nbsp;ğŸ‰ğŸ‰ One paper on action recognition is accepted by TITS 2022.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/CVPR2024.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions](https://arxiv.org/abs/2403.20254)

**Runhao Zeng**, Xiaoyong Chen, Jiaming Liang, Huisi Wu, Guangzhong Cao, Yong Guo

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
