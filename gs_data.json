{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "s3X4YHwAAAAJ&hl=en", "source": "AUTHOR_PROFILE_PAGE", "name": "Runhao Zeng (曾润浩)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=s3X4YHwAAAAJ&citpid=4", "affiliation": "Shenzhen MSU-BIT University, Tenure-track Associate Professor", "interests": ["Video Analysis", "Action Recognition", "Action Detection"], "email_domain": "@smbu.edu.cn", "homepage": "https://zengrunhao.com/", "citedby": 1543, "publications": {"s3X4YHwAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Graph convolutional networks for temporal action localization", "pub_year": "2019"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:UeHWp8X0CEIC", "num_citations": 551, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4759404064009028594", "cites_id": ["4759404064009028594"]}, "s3X4YHwAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dense regression network for video grounding", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:Y0pCki6q_DkC", "num_citations": 275, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15198293894024857717", "cites_id": ["15198293894024857717"]}, "s3X4YHwAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Location-aware graph convolutional networks for video question answering", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:zYLM7Y9cAGgC", "num_citations": 181, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5407010916751832876", "cites_id": ["5407010916751832876"]}, "s3X4YHwAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rspnet: Relative speed perception for unsupervised video representation learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:eQOLeE2rZwMC", "num_citations": 114, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12338256354188821222", "cites_id": ["12338256354188821222"]}, "s3X4YHwAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Breaking Winner-takes-all: Iterative-winners-out Networks for Weakly Supervised Temporal Action Localization", "pub_year": "2019"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:9yKSN-GCB0IC", "num_citations": 86, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15229007606561729648", "cites_id": ["15229007606561729648"]}, "s3X4YHwAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cross-modal relation-aware networks for audio-visual event localization", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:YsMSGLbcyi4C", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11722427371002175556", "cites_id": ["11722427371002175556"]}, "s3X4YHwAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Relation Attention for Temporal Action Localization", "pub_year": "2019"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:IjCSPb-OGe4C", "num_citations": 74, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10545332350516523115", "cites_id": ["10545332350516523115"]}, "s3X4YHwAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Graph Convolutional Module for Temporal Action Localization in Videos", "pub_year": "2021"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:_FxGoFyzp5QC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9564964460635204516", "cites_id": ["9564964460635204516"]}, "s3X4YHwAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Weakly-supervised multi-granularity map learning for vision-and-language navigation", "pub_year": "2022"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:roLk4NBRz8UC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10538814385598827849", "cites_id": ["10538814385598827849"]}, "s3X4YHwAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Alzheimer's Disease Classification With a Cascade Neural Network", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:W7OEmFMy1HYC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16866192739227598814", "cites_id": ["16866192739227598814"]}, "s3X4YHwAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bidirectional Posture-Appearance Interaction Network for Driver Behavior Recognition", "pub_year": "2022"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:LkGwnXOMwfcC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7273528376099025762", "cites_id": ["7273528376099025762"]}, "s3X4YHwAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models", "pub_year": "2023"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:UebtZRa9Y70C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3681392281787149522", "cites_id": ["3681392281787149522"]}, "s3X4YHwAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A thorough comparison study on adversarial attacks and defenses for common thorax disease classification in chest X-rays", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:Tyk-4Ss8FVUC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4538763751494347706", "cites_id": ["4538763751494347706"]}, "s3X4YHwAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modular graph attention network for complex visual relational reasoning", "pub_year": "2020"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:WF5omc3nYNoC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2796129404532338073", "cites_id": ["2796129404532338073"]}, "s3X4YHwAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Continual reinforcement learning with diversity exploration and adversarial self-correction", "pub_year": "2019"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:2osOgNQ5qMEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8797814844529113069", "cites_id": ["8797814844529113069"]}, "s3X4YHwAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring Motion Cues for Video Test-Time Adaptation", "pub_year": "2023"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:hqOjcs7Dif8C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14089078647352477586", "cites_id": ["14089078647352477586"]}, "s3X4YHwAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Flexible triboelectric sensor array based on 3D printed bead-on-string sacrificial layer for human-machine interactions", "pub_year": "2024"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:5nxA0vEk-isC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12781048193971921507", "cites_id": ["12781048193971921507"]}, "s3X4YHwAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:3fE2CSJIrl8C", "num_citations": 0}, "s3X4YHwAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions", "pub_year": "2024"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:8k81kl-MbHgC", "num_citations": 0}, "s3X4YHwAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DCIR: Dynamic Consistency Intrinsic Reward for Multi-Agent Reinforcement Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:0EnyYjriUFMC", "num_citations": 0}, "s3X4YHwAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation"}, "filled": false, "author_pub_id": "s3X4YHwAAAAJ:MXK_kJrjxJIC", "num_citations": 0}}, "citedby5y": 1543, "hindex": 11, "hindex5y": 11, "i10index": 11, "i10index5y": 11, "cites_per_year": {"2019": 15, "2020": 99, "2021": 295, "2022": 406, "2023": 487, "2024": 241}, "updated": "2024-07-01 08:10:13.440940"}